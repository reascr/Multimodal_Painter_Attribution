{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8485949,"sourceType":"datasetVersion","datasetId":5062127},{"sourceId":8487352,"sourceType":"datasetVersion","datasetId":5063196}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport tensorflow as tf\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:18:57.311943Z","iopub.execute_input":"2024-05-22T19:18:57.312231Z","iopub.status.idle":"2024-05-22T19:19:03.420566Z","shell.execute_reply.started":"2024-05-22T19:18:57.312202Z","shell.execute_reply":"2024-05-22T19:19:03.419683Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-22 19:18:57.998741: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-22 19:18:57.998793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-22 19:18:58.000271: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# load data frames\ndf_train = pd.read_csv('/kaggle/input/dataframes-bal/train_bal.csv')\ndf_val = pd.read_csv('/kaggle/input/dataframes-bal/val_bal.csv')\ndf_test = pd.read_csv('/kaggle/input/dataframes-bal/test_bal.csv')\n\n# load joint embeddings\n#with open('/kaggle/input/j-embeds-bal/j_embeds_train (1).pkl', 'rb') as f:\n    #v_embeds_train = pickle.load(f) \n    \n#with open('/kaggle/input/v-embeds/v_embeds_val.pkl', 'rb') as f:\n  #  v_embeds_val = pickle.load(f) \n    \nwith open('/kaggle/input/j-embeds-bal/j_embeds_test (2).pkl', 'rb') as f:\n    j_embeds_test = pickle.load(f) ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:19:03.425795Z","iopub.execute_input":"2024-05-22T19:19:03.426122Z","iopub.status.idle":"2024-05-22T19:19:04.786335Z","shell.execute_reply.started":"2024-05-22T19:19:03.426094Z","shell.execute_reply":"2024-05-22T19:19:04.785479Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(len(j_embeds_test)) # Liste aus Tensors\nprint(j_embeds_test[0].shape)\nprint(type(j_embeds_test[0]))\nprint(j_embeds_test[0].device)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:19:04.787697Z","iopub.execute_input":"2024-05-22T19:19:04.788339Z","iopub.status.idle":"2024-05-22T19:19:04.793751Z","shell.execute_reply.started":"2024-05-22T19:19:04.788302Z","shell.execute_reply":"2024-05-22T19:19:04.792756Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"89\ntorch.Size([612, 768])\n<class 'torch.Tensor'>\ncuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"### TEST: Concatentate test tensor along rows (first dimension) --> if that works, process and save training j embeds as chunks\nbatches = int(len(df_train)/len(df_test)) # 18 batches\ntest_embeds = torch.stack(j_embeds_test, dim=0) # stack it first, optionally:push to CPU and use an operation for concatenating numpy arrays\n\nconcatenated_tensor = test_embeds # start with normal tensor\nfor i in range(batches):\n    concatenated_tensor = torch.cat((concatenated_tensor, test_embeds), dim=0) # add another batch\n\nprint(\"Concatenated tensor along rows:\")\n\nprint(concatenated_tensor.shape) # LÖSUNG: j_embeds_train in chunks extrahieren und speichern, dann unten (eine Zelle weiter) auf cpu pushen. Reicht aus!\n# geht nut einmal, dann cuda out of memory\nconcatenated_tensor = concatenated_tensor.cpu().numpy()\nprint(concatenated_tensor.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:19:06.749758Z","iopub.execute_input":"2024-05-22T19:19:06.750668Z","iopub.status.idle":"2024-05-22T19:19:10.129563Z","shell.execute_reply.started":"2024-05-22T19:19:06.750635Z","shell.execute_reply":"2024-05-22T19:19:10.128545Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Concatenated tensor along rows:\ntorch.Size([1691, 612, 768])\n(1691, 612, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = torch.stack(j_embeds_test[:70], dim=0).cpu().numpy()\nX_val = torch.stack(j_embeds_test[70:80], dim=0).cpu().numpy()\nX_test = torch.stack(j_embeds_test[80:89], dim=0).cpu().numpy()\nprint(X_train.shape, X_val.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:19:18.297427Z","iopub.execute_input":"2024-05-22T19:19:18.298285Z","iopub.status.idle":"2024-05-22T19:19:18.420207Z","shell.execute_reply.started":"2024-05-22T19:19:18.298253Z","shell.execute_reply":"2024-05-22T19:19:18.419241Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(70, 612, 768) (10, 612, 768) (9, 612, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"# convert labels to numerical values\nlabel_encoder = LabelEncoder()\nlabels = df_test['AUTHOR'].tolist()\ny_train = labels[:70]\ny_val = labels[70:80]\ny_test = labels[80:89]\n\ny_train = label_encoder.fit_transform(y_train)\ny_val = label_encoder.transform(y_val)\ny_test = label_encoder.transform(y_test)\nprint(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:19:21.392813Z","iopub.execute_input":"2024-05-22T19:19:21.393701Z","iopub.status.idle":"2024-05-22T19:19:21.406519Z","shell.execute_reply.started":"2024-05-22T19:19:21.393670Z","shell.execute_reply":"2024-05-22T19:19:21.405521Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[9 5 1 3 8 4 6 9 9]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the model\ntf.random.set_seed(42)\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(612, 768)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val)) # decrease epochs if needed\n\n# Evaluate on validation set\nval_loss, val_accuracy = model.evaluate(X_val, y_val)\nprint(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n\n# Evaluate on test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:19:23.059594Z","iopub.execute_input":"2024-05-22T19:19:23.060317Z","iopub.status.idle":"2024-05-22T19:19:34.940778Z","shell.execute_reply.started":"2024-05-22T19:19:23.060281Z","shell.execute_reply":"2024-05-22T19:19:34.939812Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0781 - loss: 2.4064","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716405567.191020    3006 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1716405567.203811    3006 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.0737 - loss: 4.8592 - val_accuracy: 0.2000 - val_loss: 44.6265\nEpoch 2/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.1369 - loss: 45.7979 - val_accuracy: 0.1000 - val_loss: 56.2127\nEpoch 3/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.1906 - loss: 51.3644 - val_accuracy: 0.2000 - val_loss: 55.2003\nEpoch 4/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2929 - loss: 37.6575 - val_accuracy: 0.2000 - val_loss: 23.9204\nEpoch 5/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5728 - loss: 13.2881 - val_accuracy: 0.2000 - val_loss: 20.2950\nEpoch 6/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6759 - loss: 5.5925 - val_accuracy: 0.2000 - val_loss: 24.2889\nEpoch 7/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7253 - loss: 2.8993 - val_accuracy: 0.2000 - val_loss: 28.4521\nEpoch 8/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6759 - loss: 3.3770 - val_accuracy: 0.3000 - val_loss: 22.3780\nEpoch 9/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8527 - loss: 0.9151 - val_accuracy: 0.0000e+00 - val_loss: 21.8959\nEpoch 10/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8527 - loss: 0.8918 - val_accuracy: 0.1000 - val_loss: 21.0621\nEpoch 11/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9263 - loss: 0.2804 - val_accuracy: 0.1000 - val_loss: 20.0949\nEpoch 12/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9705 - loss: 0.1656 - val_accuracy: 0.1000 - val_loss: 19.2161\nEpoch 13/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9853 - loss: 0.1271 - val_accuracy: 0.2000 - val_loss: 19.2997\nEpoch 14/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9853 - loss: 0.0841 - val_accuracy: 0.2000 - val_loss: 19.5113\nEpoch 15/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.2000 - val_loss: 19.8397\nEpoch 16/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.7748e-04 - val_accuracy: 0.2000 - val_loss: 20.0666\nEpoch 17/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.2000 - val_loss: 20.1375\nEpoch 18/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.2000 - val_loss: 19.9826\nEpoch 19/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.2000 - val_loss: 19.7825\nEpoch 20/20\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.6521e-04 - val_accuracy: 0.2000 - val_loss: 19.6204\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2000 - loss: 19.6204\nValidation Loss: 19.620410919189453, Validation Accuracy: 0.20000000298023224\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849ms/step - accuracy: 0.2222 - loss: 24.5498\nTest Loss: 24.54976463317871, Test Accuracy: 0.2222222238779068\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Besser als mit visuellen Features und über Chance Performance. Allerdings nur mit 109 Datensätzen trainiert. Wie kann man sichergehen, dass das Model nicht nur die Textfeatures benutzt? ","metadata":{}}]}