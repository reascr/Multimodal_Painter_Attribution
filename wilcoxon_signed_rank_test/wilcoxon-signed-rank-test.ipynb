{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8538450,"sourceType":"datasetVersion","datasetId":5100519},{"sourceId":8539005,"sourceType":"datasetVersion","datasetId":5100943}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Wilcoxon Signed-Rank Test \n\nTo test whether the multimodal model performs significantly better than the baselines (visual or textual features only), a wilcoxon signed-rank test will be conducted.\n\n**Null hypothesis 1:** The test accuracy samples obtained by training a classifier on joint visual-textual features and the accuracy samples obtained by training a classifier on visual features only come from the same distribution (do not significant differences).\n\n**Null hypothesis 2:** The test accuracy samples obtained by training a classifier on joint visual-textual features and the accuracy samples obtained by training a classifier on textual features only come from the same distribution (do not significant differences).","metadata":{}},{"cell_type":"code","source":"import scipy.stats as stats\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-28T10:08:59.769956Z","iopub.execute_input":"2024-05-28T10:08:59.770405Z","iopub.status.idle":"2024-05-28T10:09:01.021998Z","shell.execute_reply.started":"2024-05-28T10:08:59.770369Z","shell.execute_reply":"2024-05-28T10:09:01.020962Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load data\n#group1 = [456, 564, 54, 554, 54, 51, 1, 12, 45, 5]  #represents the test accuracies of the multimodal model\n#group2 = [65, 87, 456, 564, 456, 564, 564, 6, 4, 564] # baseline model\n\n# test and validation accuracies (for all epochs) for visual features\ntest_accuracies_visual = pd.read_csv(\"/kaggle/input/results-visual-features-seeds/visual_results.csv\")\ntest_acc_visual = test_accuracies_visual['test_accuracy'].tolist()\nprint(test_acc_visual)\n\nval_accuracies_all_epochs_visual = pd.read_csv(\"/kaggle/input/results-visual-features-seeds/visual_all_val_accuracies.csv\")\nval_accuracies_all_epochs_visual = val_accuracies_all_epochs_visual.drop(val_accuracies_all_epochs_visual.columns[0],  axis=1)\nval_accuracies_all_epochs_visual.head()\n\n# test and validation accuracies (for all epochs) for joint features\ntest_accuracies_joint = pd.read_csv(\"/kaggle/input/results-joint-features-seeds/joint_results.csv\")\ntest_acc_joint = test_accuracies_joint['test_accuracy'].tolist()\nprint(test_acc_joint)\n\nval_accuracies_all_epochs_joint = pd.read_csv(\"/kaggle/input/results-joint-features-seeds/joint_all_val_accuracies.csv\")\nval_accuracies_all_epochs_joint = val_accuracies_all_epochs_joint.drop(val_accuracies_all_epochs_joint.columns[0],  axis=1)\nval_accuracies_all_epochs_joint.head()\n\n# test and validation accuracies (for all epochs) for textual features","metadata":{"execution":{"iopub.status.busy":"2024-05-28T10:13:27.659919Z","iopub.execute_input":"2024-05-28T10:13:27.660344Z","iopub.status.idle":"2024-05-28T10:13:27.711020Z","shell.execute_reply.started":"2024-05-28T10:13:27.660313Z","shell.execute_reply":"2024-05-28T10:13:27.709749Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[0.4382022619247436, 0.4719101190567016, 0.449438214302063, 0.4157303273677826, 0.3595505654811859, 0.3932584226131439, 0.4269662797451019, 0.4044943749904632, 0.4606741666793823, 0.449438214302063]\n[0.6629213690757751, 0.6067415475845337, 0.6404494643211365, 0.6404494643211365, 0.6516854166984558, 0.6516854166984558, 0.6741573214530945, 0.6853932738304138, 0.5730336904525757, 0.7078651785850525]\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"    epoch 1   epoch 2   epoch 3   epoch 4   epoch 5   epoch 6   epoch 7  \\\n0  0.101124  0.235955  0.280899  0.382022  0.460674  0.550562  0.629214   \n1  0.157303  0.269663  0.370787  0.348315  0.404494  0.494382  0.651685   \n2  0.191011  0.303371  0.303371  0.494382  0.539326  0.584270  0.528090   \n3  0.224719  0.280899  0.235955  0.337079  0.471910  0.573034  0.651685   \n4  0.067416  0.146067  0.247191  0.314607  0.460674  0.539326  0.629214   \n\n    epoch 8   epoch 9  epoch 10  epoch 11  epoch 12  epoch 13  epoch 14  \\\n0  0.629214  0.662921  0.629214  0.662921  0.707865  0.685393  0.617977   \n1  0.584270  0.595506  0.651685  0.685393  0.685393  0.707865  0.696629   \n2  0.595506  0.674157  0.651685  0.640449  0.674157  0.662921       NaN   \n3  0.719101  0.707865  0.696629  0.719101  0.719101  0.662921  0.696629   \n4  0.662921  0.707865  0.674157  0.696629  0.662921  0.674157  0.707865   \n\n   epoch 15  \n0  0.629214  \n1  0.640449  \n2       NaN  \n3  0.696629  \n4  0.685393  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch 1</th>\n      <th>epoch 2</th>\n      <th>epoch 3</th>\n      <th>epoch 4</th>\n      <th>epoch 5</th>\n      <th>epoch 6</th>\n      <th>epoch 7</th>\n      <th>epoch 8</th>\n      <th>epoch 9</th>\n      <th>epoch 10</th>\n      <th>epoch 11</th>\n      <th>epoch 12</th>\n      <th>epoch 13</th>\n      <th>epoch 14</th>\n      <th>epoch 15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.101124</td>\n      <td>0.235955</td>\n      <td>0.280899</td>\n      <td>0.382022</td>\n      <td>0.460674</td>\n      <td>0.550562</td>\n      <td>0.629214</td>\n      <td>0.629214</td>\n      <td>0.662921</td>\n      <td>0.629214</td>\n      <td>0.662921</td>\n      <td>0.707865</td>\n      <td>0.685393</td>\n      <td>0.617977</td>\n      <td>0.629214</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.157303</td>\n      <td>0.269663</td>\n      <td>0.370787</td>\n      <td>0.348315</td>\n      <td>0.404494</td>\n      <td>0.494382</td>\n      <td>0.651685</td>\n      <td>0.584270</td>\n      <td>0.595506</td>\n      <td>0.651685</td>\n      <td>0.685393</td>\n      <td>0.685393</td>\n      <td>0.707865</td>\n      <td>0.696629</td>\n      <td>0.640449</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.191011</td>\n      <td>0.303371</td>\n      <td>0.303371</td>\n      <td>0.494382</td>\n      <td>0.539326</td>\n      <td>0.584270</td>\n      <td>0.528090</td>\n      <td>0.595506</td>\n      <td>0.674157</td>\n      <td>0.651685</td>\n      <td>0.640449</td>\n      <td>0.674157</td>\n      <td>0.662921</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.224719</td>\n      <td>0.280899</td>\n      <td>0.235955</td>\n      <td>0.337079</td>\n      <td>0.471910</td>\n      <td>0.573034</td>\n      <td>0.651685</td>\n      <td>0.719101</td>\n      <td>0.707865</td>\n      <td>0.696629</td>\n      <td>0.719101</td>\n      <td>0.719101</td>\n      <td>0.662921</td>\n      <td>0.696629</td>\n      <td>0.696629</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.067416</td>\n      <td>0.146067</td>\n      <td>0.247191</td>\n      <td>0.314607</td>\n      <td>0.460674</td>\n      <td>0.539326</td>\n      <td>0.629214</td>\n      <td>0.662921</td>\n      <td>0.707865</td>\n      <td>0.674157</td>\n      <td>0.696629</td>\n      <td>0.662921</td>\n      <td>0.674157</td>\n      <td>0.707865</td>\n      <td>0.685393</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# conduct significance testing for visual baseline\n\n#stat, p_value = stats.wilcoxon(group1, group2, alternative='greater') \n\nstat, p_value = stats.wilcoxon(test_acc_joint, test_acc_visual, alternative='greater') \n\nprint(f'Wilcoxon Signed-Rank Test: stat={stat}, p-value={p_value}')\n\nif p_value < 0.05:\n    print(\"We reject the null hypothesis 1. The multimodal model performs significantly better than the visual baseline.\")\nelse:\n    print(\"We cannot reject the null hypothesis 1. The multimodal model does not perform significantly better than the visual baseline.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T10:13:42.904791Z","iopub.execute_input":"2024-05-28T10:13:42.905846Z","iopub.status.idle":"2024-05-28T10:13:42.917131Z","shell.execute_reply.started":"2024-05-28T10:13:42.905792Z","shell.execute_reply":"2024-05-28T10:13:42.916034Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Wilcoxon Signed-Rank Test: stat=55.0, p-value=0.0009765625\nWe reject the null hypothesis 1. The multimodal model performs significantly better than the visual baseline.\n","output_type":"stream"}]},{"cell_type":"code","source":"# conduct significance testing for textual baseline\n\nstat, p_value = stats.wilcoxon(group1, group2, alternative='greater') \n\nprint(f'Wilcoxon Signed-Rank Test: stat={stat}, p-value={p_value}')\n\nif p_value < 0.05:\n    print(\"We reject the null hypothesis 2. The multimodal model performs significantly better than the textual baseline.\")\nelse:\n    print(\"We cannot reject the null hypothesis 2. The multimodal model does not perform significantly better than the textual baseline.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot overall results for test accuracies\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot overall results for validation accuracies","metadata":{},"execution_count":null,"outputs":[]}]}