{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T19:48:28.966137Z",
     "iopub.status.busy": "2024-05-20T19:48:28.965321Z",
     "iopub.status.idle": "2024-05-20T19:48:44.988118Z",
     "shell.execute_reply": "2024-05-20T19:48:44.987227Z",
     "shell.execute_reply.started": "2024-05-20T19:48:28.966101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 19:48:31.276778: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-20 19:48:31.276875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-20 19:48:31.378815: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T19:48:44.990100Z",
     "iopub.status.busy": "2024-05-20T19:48:44.989573Z",
     "iopub.status.idle": "2024-05-20T19:48:53.126223Z",
     "shell.execute_reply": "2024-05-20T19:48:53.125128Z",
     "shell.execute_reply.started": "2024-05-20T19:48:44.990074Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data frames\n",
    "df_train = pd.read_csv('/kaggle/input/dataframes/train.csv')\n",
    "df_val = pd.read_csv('/kaggle/input/dataframes/val.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/dataframes/val.csv')\n",
    "\n",
    "# load joint embeddings\n",
    "#with open('/kaggle/input/v-embeds/v_embeds_train.pkl', 'rb') as f:\n",
    "   # v_embeds_train = pickle.load(f) \n",
    "    \n",
    "#with open('/kaggle/input/v-embeds/v_embeds_val.pkl', 'rb') as f:\n",
    "  #  v_embeds_val = pickle.load(f) \n",
    "    \n",
    "with open('/kaggle/input/j-embeds/j_embeds_test.pkl', 'rb') as f:\n",
    "    j_embeds_test = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T19:49:13.408200Z",
     "iopub.status.busy": "2024-05-20T19:49:13.407838Z",
     "iopub.status.idle": "2024-05-20T19:49:13.413752Z",
     "shell.execute_reply": "2024-05-20T19:49:13.412800Z",
     "shell.execute_reply.started": "2024-05-20T19:49:13.408171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "print(len(j_embeds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T19:51:23.467206Z",
     "iopub.status.busy": "2024-05-20T19:51:23.466485Z",
     "iopub.status.idle": "2024-05-20T19:51:23.635710Z",
     "shell.execute_reply": "2024-05-20T19:51:23.634672Z",
     "shell.execute_reply.started": "2024-05-20T19:51:23.467175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 612, 768) (10, 612, 768) (9, 612, 768)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.stack(j_embeds_test[:90], dim=0).cpu().numpy()\n",
    "X_val = torch.stack(j_embeds_test[90:100], dim=0).cpu().numpy()\n",
    "X_test = torch.stack(j_embeds_test[100:], dim=0).cpu().numpy()\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T19:56:13.908888Z",
     "iopub.status.busy": "2024-05-20T19:56:13.908492Z",
     "iopub.status.idle": "2024-05-20T19:56:13.916852Z",
     "shell.execute_reply": "2024-05-20T19:56:13.915739Z",
     "shell.execute_reply.started": "2024-05-20T19:56:13.908858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 4 5 3 8 8 4 6]\n"
     ]
    }
   ],
   "source": [
    "# convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "labels = df_test['AUTHOR'].tolist()\n",
    "y_train = labels[:90]\n",
    "y_val = labels[90:100]\n",
    "y_test = labels[100:]\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T19:57:06.977086Z",
     "iopub.status.busy": "2024-05-20T19:57:06.976662Z",
     "iopub.status.idle": "2024-05-20T19:57:18.056454Z",
     "shell.execute_reply": "2024-05-20T19:57:18.055572Z",
     "shell.execute_reply.started": "2024-05-20T19:57:06.977055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.0625 - loss: 2.2881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716235031.305524     494 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1716235031.322181     494 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.0607 - loss: 33.4969 - val_accuracy: 0.1000 - val_loss: 34.0372\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2896 - loss: 29.4345 - val_accuracy: 0.0000e+00 - val_loss: 40.3626\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3139 - loss: 22.8954 - val_accuracy: 0.2000 - val_loss: 19.4853\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4922 - loss: 8.9841 - val_accuracy: 0.2000 - val_loss: 16.0413\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6576 - loss: 5.5278 - val_accuracy: 0.0000e+00 - val_loss: 23.3076\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7612 - loss: 3.2455 - val_accuracy: 0.0000e+00 - val_loss: 26.7728\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8803 - loss: 0.9271 - val_accuracy: 0.0000e+00 - val_loss: 27.1850\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9087 - loss: 1.2769 - val_accuracy: 0.0000e+00 - val_loss: 32.4685\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9393 - loss: 0.7380 - val_accuracy: 0.2000 - val_loss: 30.7365\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9622 - loss: 0.0843 - val_accuracy: 0.2000 - val_loss: 28.3448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2000 - loss: 28.3448\n",
      "Validation Loss: 28.34479331970215, Validation Accuracy: 0.20000000298023224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783ms/step - accuracy: 0.2222 - loss: 23.5122\n",
      "Test Loss: 23.51221466064453, Test Accuracy: 0.2222222238779068\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(612, 768)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besser als mit visuellen Features und über Chance Performance. Allerdings nur mit 109 Datensätzen trainiert. Wie kann man sichergehen, dass das Model nicht nur die Textfeatures benutzt? "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5049287,
     "sourceId": 8468551,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5050784,
     "sourceId": 8470576,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
